{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Install NLTK Library**"
      ],
      "metadata": {
        "id": "_2INL9ulB_5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaTjB7fxAXEB",
        "outputId": "234e9fad-035e-423a-fa75-913b9347521c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Import Required Libraries**"
      ],
      "metadata": {
        "id": "oK__w1eaCAQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "XhOl9thsAe0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Download NLTK Resources**"
      ],
      "metadata": {
        "id": "CQ19jvx9CAvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sdflBH1AeyQ",
        "outputId": "956543b8-adff-4357-d846-fcb5771e6b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Define the Stemming Function**"
      ],
      "metadata": {
        "id": "DKUPOvcpCBUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_words(words):\n",
        "    ps = PorterStemmer()\n",
        "    return [ps.stem(word) for word in words]\n"
      ],
      "metadata": {
        "id": "MJlRcR8QAewH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Define a Function to Map POS Tags for Lemmatization**"
      ],
      "metadata": {
        "id": "DBnP1IOsCBx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "F2SevZTmAetv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Define the Lemmatization Function**"
      ],
      "metadata": {
        "id": "Yj5jaOg4CCM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_words(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]"
      ],
      "metadata": {
        "id": "ysHJZF7KAerf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Define a Function to Preprocess Text**"
      ],
      "metadata": {
        "id": "bhaexLMWCClB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())"
      ],
      "metadata": {
        "id": "MOGuaDu2AepA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Apply the Preprocessing, Stemming, and Lemmatization**"
      ],
      "metadata": {
        "id": "WxuOrSL8CDA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"She sells seashells by the seashore.\"\n",
        "words = preprocess_text(text)\n",
        "\n",
        "stemmed_words = stem_words(words)\n",
        "lemmatized_words = lemmatize_words(words)\n",
        "\n",
        "print(\"Original Sentence:\", text)\n",
        "print(\"Stemmed Sentence:\", stemmed_words)\n",
        "print(\"Lemmatized Sentence:\", lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdKAhG7GAemf",
        "outputId": "73ce3b45-d090-4961-897c-5e750f561643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: She sells seashells by the seashore.\n",
            "Stemmed Sentence: ['she', 'sell', 'seashel', 'by', 'the', 'seashor', '.']\n",
            "Lemmatized Sentence: ['she', 'sell', 'seashell', 'by', 'the', 'seashore', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLqhvcN-Aej_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUGdg43cAebn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}